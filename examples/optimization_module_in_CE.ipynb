{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a basic Cluster Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from monty.serialization import loadfn, dumpfn\n",
    "from pymatgen import Structure\n",
    "from smol.cofe import ClusterSubspace, StructureWrangler, ClusterExpansion\n",
    "from smol.cofe.extern import EwaldTerm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim = Structure.from_file('./data/LiF.cif')\n",
    "ro = {'Li+':{'Li+':1/3, 'Mn3+':1/3,  'Ti4+':1/3}, 'F-':{'O2-':1.0}}\n",
    "\n",
    "prim.replace_species(ro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the DFT data of Li-Mn-Ti-O system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 structures map to the lattice\n"
     ]
    }
   ],
   "source": [
    "\n",
    "calc_data = []\n",
    "# calc_indices = []\n",
    "\n",
    "with open('./data/MnTi_O.json', 'r') as fin: calc_data = json.loads(fin.read())\n",
    "\n",
    "\n",
    "# print(calc_data)\n",
    "\n",
    "valid_structs = []\n",
    "weights = []\n",
    "for calc_i, calc in enumerate(calc_data):\n",
    "\n",
    "    struct = Structure.from_dict(calc['s'])\n",
    "    valid_structs.append((struct, calc['toten']))\n",
    "\n",
    "print(\"{}/{} structures map to the lattice\".format(len(valid_structs), len(calc_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) The prim structure\n",
    "The prim structure defines the **configurational space** for the Cluster Expansion. \n",
    "The **configurational space** is defined by the site **compositional spaces** and the crystal symetries of the prim structure.\n",
    "The occupancy of the sites determine site **compositional spaces**. Sites are **active** if they have compositional degrees of freedom.\n",
    "\n",
    "\n",
    "Active sites have fractional compositions. Vacancies are allowed in sites where the composition does not sum to one.\n",
    "\n",
    "0. Is active. The allowed species are: Li+ and vacancies.\n",
    "1. Is active. The allowed species are: Ni3+ and Ni4+.\n",
    "2. Is not active. Only O2- is allowed.\n",
    "3. Is not active. Only O2- is allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Formula (Li0.33333333 Ti0.33333333 Mn0.33333333 O1)\n",
      "Reduced Formula: Li0.33333333Ti0.33333333Mn0.33333333O1\n",
      "abc   :   2.969848   2.969848   2.969848\n",
      "angles:  60.000000  60.000000  60.000000\n",
      "Sites (2)\n",
      "  #  SP                                   a    b    c\n",
      "---  ---------------------------------  ---  ---  ---\n",
      "  0  Li+:0.333, Ti4+:0.333, Mn3+:0.333  0    0    0\n",
      "  1  O2-                                0.5  0.5  0.5\n"
     ]
    }
   ],
   "source": [
    "print(prim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) The cluster subspace\n",
    "The `ClusterSubspace` represents all the orbits (groups of equivalent clusters) that will be considered when fitting the cluster expansion. Its main purpose is to compute the **correlations functions** for each included orbit given a structure in the compositional space defined by the prim.\n",
    "\n",
    "In order to do be able to compute the correlation functions, the given structure must match the prim structure in a \"crystallographic\" sense but allowing for compositional degrees of freedom in the \"active\" sites.\n",
    "\n",
    "A cluster subspace most easily created by providing:\n",
    "1. The prim structure representing the configurational space.\n",
    "2. A set of cutoff radii for each size of orbit we want to consider.\n",
    "3. A type of site basis function to use.\n",
    "\n",
    "There are more options allowed by the code to fine grain and tune. See other notebooks for advanced use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClusterBasis: [Prim Composition] Li+0.33333333 Mn3+0.33333333 Ti4+0.33333333 O2-1\n",
      "    [Size] 0\n",
      "      [Orbit] id: 0  orderings: 1\n",
      "    [Size] 1\n",
      "      [Orbit] id: 1  orderings: 2   multiplicity: 1    no. symops: 48  \n",
      "              [Base Cluster] Radius: 0.0   Centroid: [0. 0. 0.]         Points: [[0. 0. 0.]]         \n",
      "    [Size] 2\n",
      "      [Orbit] id: 2  orderings: 3   multiplicity: 6    no. symops: 8   \n",
      "              [Base Cluster] Radius: 2.97  Centroid: [0.  0.  0.5]      Points: [[0. 0. 1.]  [0. 0. 0.]]                  \n",
      "      [Orbit] id: 3  orderings: 3   multiplicity: 3    no. symops: 16  \n",
      "              [Base Cluster] Radius: 4.2   Centroid: [0.5 0.5 0.5]      Points: [[1. 1. 0.]  [0. 0. 1.]]                  \n",
      "      [Orbit] id: 4  orderings: 3   multiplicity: 12   no. symops: 4   \n",
      "              [Base Cluster] Radius: 5.14  Centroid: [0.  0.5 0.5]      Points: [[0. 1. 1.]  [0. 0. 0.]]                  \n",
      "      [Orbit] id: 5  orderings: 3   multiplicity: 6    no. symops: 8   \n",
      "              [Base Cluster] Radius: 5.94  Centroid: [0. 0. 0.]         Points: [[ 0.  0.  1.]  [ 0.  0. -1.]]            \n",
      "      [Orbit] id: 6  orderings: 3   multiplicity: 12   no. symops: 4   \n",
      "              [Base Cluster] Radius: 6.64  Centroid: [0.5 0.  0.5]      Points: [[ 1.  1.  0.]  [ 0. -1.  1.]]            \n",
      "    [Size] 3\n",
      "      [Orbit] id: 7  orderings: 4   multiplicity: 8    no. symops: 6   \n",
      "              [Base Cluster] Radius: 2.97  Centroid: [0.   0.67 0.67]   Points: [[0. 1. 1.]  [0. 1. 0.]  [0. 0. 1.]]                           \n",
      "    [Size] 4\n",
      "      [Orbit] id: 8  orderings: 5   multiplicity: 2    no. symops: 24  \n",
      "              [Base Cluster] Radius: 2.97  Centroid: [0.75 0.75 0.75]   Points: [[1. 1. 1.]  [1. 1. 0.]  [1. 0. 1.]  [0. 1. 1.]]                                    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "subspace = ClusterSubspace.from_radii(prim,\n",
    "                                      radii={2: 7.1, 3: 4, 4:4}, # will include orbits of 2 and 3 sites.\n",
    "                                      basis='indicator',\n",
    "                                      supercell_size='volume')\n",
    "\n",
    "# supercell_size specifies the method to determine the supercell size\n",
    "# when trying to match a structure.\n",
    "# (See pymatgen.structure_mathcer.StructureMatcher for more info)\n",
    "\n",
    "# subspace.add_external_term(EwaldTerm(eta=None))\n",
    "\n",
    "print(subspace) # single site and empty orbits are always included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1) Computing a correlation vector.\n",
    "A correlation vector for a specific structure (represents the feature vector) used to train and predict target values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation vector for a structure with composition Li+16 Mn3+16 O2-32 is: \n",
      "[ 1.00000000e+00  5.00000000e-01  0.00000000e+00  2.18750000e-01\n",
      "  0.00000000e+00  0.00000000e+00  2.70833333e-01  0.00000000e+00\n",
      "  0.00000000e+00  2.60416667e-01  0.00000000e+00  0.00000000e+00\n",
      "  2.50000000e-01  0.00000000e+00  0.00000000e+00  2.18750000e-01\n",
      "  0.00000000e+00  0.00000000e+00  7.42187500e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.56250000e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00 -5.07478809e+01]\n"
     ]
    }
   ],
   "source": [
    "structure = Structure.from_dict(calc_data[0]['s'])\n",
    "corr = subspace.corr_from_structure(structure)\n",
    "\n",
    "print(f'The correlation vector for a structure with'\n",
    "      f' composition {structure.composition} is: '\n",
    "      f'\\n{corr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) The structure wrangler\n",
    "The `StructureWrangler` is a class that will is used to create and organize the data that will be used to train (and possibly test) the cluster expansion. It makes sure that all the supplied structures appropriately match the prim structure, and obtains the necessary information to correctly normalize target properties (such as energy) necessary for training.\n",
    "\n",
    "Matching relaxed structures can be a tricky problem, especially for ionic systems with vacancies. See the notebook on structure matching for tips on how to tweak parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 0/630\n",
      "processed: 1/630\n",
      "processed: 2/630\n",
      "processed: 3/630\n",
      "processed: 4/630\n",
      "processed: 5/630\n",
      "processed: 6/630\n",
      "processed: 7/630\n",
      "processed: 8/630\n",
      "processed: 9/630\n",
      "processed: 10/630\n",
      "processed: 11/630\n",
      "processed: 12/630\n",
      "processed: 13/630\n",
      "processed: 14/630\n",
      "processed: 15/630\n",
      "processed: 16/630\n",
      "processed: 17/630\n",
      "processed: 18/630\n",
      "processed: 19/630\n",
      "processed: 20/630\n",
      "processed: 21/630\n",
      "processed: 22/630\n",
      "processed: 23/630\n",
      "processed: 24/630\n",
      "processed: 25/630\n",
      "processed: 26/630\n",
      "processed: 27/630\n",
      "processed: 28/630\n",
      "processed: 29/630\n",
      "processed: 30/630\n",
      "processed: 31/630\n",
      "processed: 32/630\n",
      "processed: 33/630\n",
      "processed: 34/630\n",
      "processed: 35/630\n",
      "processed: 36/630\n",
      "processed: 37/630\n",
      "processed: 38/630\n",
      "processed: 39/630\n",
      "processed: 40/630\n",
      "processed: 41/630\n",
      "processed: 42/630\n",
      "processed: 43/630\n",
      "processed: 44/630\n",
      "processed: 45/630\n",
      "processed: 46/630\n",
      "processed: 47/630\n",
      "processed: 48/630\n",
      "processed: 49/630\n",
      "processed: 50/630\n",
      "processed: 51/630\n",
      "processed: 52/630\n",
      "processed: 53/630\n",
      "processed: 54/630\n",
      "processed: 55/630\n",
      "processed: 56/630\n",
      "processed: 57/630\n",
      "processed: 58/630\n",
      "processed: 59/630\n",
      "processed: 60/630\n",
      "processed: 61/630\n",
      "processed: 62/630\n",
      "processed: 63/630\n",
      "processed: 64/630\n",
      "processed: 65/630\n",
      "processed: 66/630\n",
      "processed: 67/630\n",
      "processed: 68/630\n",
      "processed: 69/630\n",
      "processed: 70/630\n",
      "processed: 71/630\n",
      "processed: 72/630\n",
      "processed: 73/630\n",
      "processed: 74/630\n",
      "processed: 75/630\n",
      "processed: 76/630\n",
      "processed: 77/630\n",
      "processed: 78/630\n",
      "processed: 79/630\n",
      "processed: 80/630\n",
      "processed: 81/630\n",
      "processed: 82/630\n",
      "processed: 83/630\n",
      "processed: 84/630\n",
      "processed: 85/630\n",
      "processed: 86/630\n",
      "processed: 87/630\n",
      "processed: 88/630\n",
      "processed: 89/630\n",
      "processed: 90/630\n",
      "processed: 91/630\n",
      "processed: 92/630\n",
      "processed: 93/630\n",
      "processed: 94/630\n",
      "processed: 95/630\n",
      "processed: 96/630\n",
      "processed: 97/630\n",
      "processed: 98/630\n",
      "processed: 99/630\n",
      "processed: 100/630\n",
      "processed: 101/630\n",
      "processed: 102/630\n",
      "processed: 103/630\n",
      "processed: 104/630\n",
      "processed: 105/630\n",
      "processed: 106/630\n",
      "processed: 107/630\n",
      "processed: 108/630\n",
      "processed: 109/630\n",
      "processed: 110/630\n",
      "processed: 111/630\n",
      "processed: 112/630\n",
      "processed: 113/630\n",
      "processed: 114/630\n",
      "processed: 115/630\n",
      "processed: 116/630\n",
      "processed: 117/630\n",
      "processed: 118/630\n",
      "processed: 119/630\n",
      "processed: 120/630\n",
      "processed: 121/630\n",
      "processed: 122/630\n",
      "processed: 123/630\n",
      "processed: 124/630\n",
      "processed: 125/630\n",
      "processed: 126/630\n",
      "processed: 127/630\n",
      "processed: 128/630\n",
      "processed: 129/630\n",
      "processed: 130/630\n",
      "processed: 131/630\n",
      "processed: 132/630\n",
      "processed: 133/630\n",
      "processed: 134/630\n",
      "processed: 135/630\n",
      "processed: 136/630\n",
      "processed: 137/630\n",
      "processed: 138/630\n",
      "processed: 139/630\n",
      "processed: 140/630\n",
      "processed: 141/630\n",
      "processed: 142/630\n",
      "processed: 143/630\n",
      "processed: 144/630\n",
      "processed: 145/630\n",
      "processed: 146/630\n",
      "processed: 147/630\n",
      "processed: 148/630\n",
      "processed: 149/630\n",
      "processed: 150/630\n",
      "processed: 151/630\n",
      "processed: 152/630\n",
      "processed: 153/630\n",
      "processed: 154/630\n",
      "processed: 155/630\n",
      "processed: 156/630\n",
      "processed: 157/630\n",
      "processed: 158/630\n",
      "processed: 159/630\n",
      "processed: 160/630\n",
      "processed: 161/630\n",
      "processed: 162/630\n",
      "processed: 163/630\n",
      "processed: 164/630\n",
      "processed: 165/630\n",
      "processed: 166/630\n",
      "processed: 167/630\n",
      "processed: 168/630\n",
      "processed: 169/630\n",
      "processed: 170/630\n",
      "processed: 171/630\n",
      "processed: 172/630\n",
      "processed: 173/630\n",
      "processed: 174/630\n",
      "processed: 175/630\n",
      "processed: 176/630\n",
      "processed: 177/630\n",
      "processed: 178/630\n",
      "processed: 179/630\n",
      "processed: 180/630\n",
      "processed: 181/630\n",
      "processed: 182/630\n",
      "processed: 183/630\n",
      "processed: 184/630\n",
      "processed: 185/630\n",
      "processed: 186/630\n",
      "processed: 187/630\n",
      "processed: 188/630\n",
      "processed: 189/630\n",
      "processed: 190/630\n",
      "processed: 191/630\n",
      "processed: 192/630\n",
      "processed: 193/630\n",
      "processed: 194/630\n",
      "processed: 195/630\n",
      "processed: 196/630\n",
      "processed: 197/630\n",
      "processed: 198/630\n",
      "processed: 199/630\n",
      "processed: 200/630\n",
      "processed: 201/630\n",
      "processed: 202/630\n",
      "processed: 203/630\n",
      "processed: 204/630\n",
      "processed: 205/630\n",
      "processed: 206/630\n",
      "processed: 207/630\n",
      "processed: 208/630\n",
      "processed: 209/630\n",
      "processed: 210/630\n",
      "processed: 211/630\n",
      "processed: 212/630\n",
      "processed: 213/630\n",
      "processed: 214/630\n",
      "processed: 215/630\n",
      "processed: 216/630\n",
      "processed: 217/630\n",
      "processed: 218/630\n",
      "processed: 219/630\n",
      "processed: 220/630\n",
      "processed: 221/630\n",
      "processed: 222/630\n",
      "processed: 223/630\n",
      "processed: 224/630\n",
      "processed: 225/630\n",
      "processed: 226/630\n",
      "processed: 227/630\n",
      "processed: 228/630\n",
      "processed: 229/630\n",
      "processed: 230/630\n",
      "processed: 231/630\n",
      "processed: 232/630\n",
      "processed: 233/630\n",
      "processed: 234/630\n",
      "processed: 235/630\n",
      "processed: 236/630\n",
      "processed: 237/630\n",
      "processed: 238/630\n",
      "processed: 239/630\n",
      "processed: 240/630\n",
      "processed: 241/630\n",
      "processed: 242/630\n",
      "processed: 243/630\n",
      "processed: 244/630\n",
      "processed: 245/630\n",
      "processed: 246/630\n",
      "processed: 247/630\n",
      "processed: 248/630\n",
      "processed: 249/630\n",
      "processed: 250/630\n",
      "processed: 251/630\n",
      "processed: 252/630\n",
      "processed: 253/630\n",
      "processed: 254/630\n",
      "processed: 255/630\n",
      "processed: 256/630\n",
      "processed: 257/630\n",
      "processed: 258/630\n",
      "processed: 259/630\n",
      "processed: 260/630\n",
      "processed: 261/630\n",
      "processed: 262/630\n",
      "processed: 263/630\n",
      "processed: 264/630\n",
      "processed: 265/630\n",
      "processed: 266/630\n",
      "processed: 267/630\n",
      "processed: 268/630\n",
      "processed: 269/630\n",
      "processed: 270/630\n",
      "processed: 271/630\n",
      "processed: 272/630\n",
      "processed: 273/630\n",
      "processed: 274/630\n",
      "processed: 275/630\n",
      "processed: 276/630\n",
      "processed: 277/630\n",
      "processed: 278/630\n",
      "processed: 279/630\n",
      "processed: 280/630\n",
      "processed: 281/630\n",
      "processed: 282/630\n",
      "processed: 283/630\n",
      "processed: 284/630\n",
      "processed: 285/630\n",
      "processed: 286/630\n",
      "processed: 287/630\n",
      "processed: 288/630\n",
      "processed: 289/630\n",
      "processed: 290/630\n",
      "processed: 291/630\n",
      "processed: 292/630\n",
      "processed: 293/630\n",
      "processed: 294/630\n",
      "processed: 295/630\n",
      "processed: 296/630\n",
      "processed: 297/630\n",
      "processed: 298/630\n",
      "processed: 299/630\n",
      "processed: 300/630\n",
      "processed: 301/630\n",
      "processed: 302/630\n",
      "processed: 303/630\n",
      "processed: 304/630\n",
      "processed: 305/630\n",
      "processed: 306/630\n",
      "processed: 307/630\n",
      "processed: 308/630\n",
      "processed: 309/630\n",
      "processed: 310/630\n",
      "processed: 311/630\n",
      "processed: 312/630\n",
      "processed: 313/630\n",
      "processed: 314/630\n",
      "processed: 315/630\n",
      "processed: 316/630\n",
      "processed: 317/630\n",
      "processed: 318/630\n",
      "processed: 319/630\n",
      "processed: 320/630\n",
      "processed: 321/630\n",
      "processed: 322/630\n",
      "processed: 323/630\n",
      "processed: 324/630\n",
      "processed: 325/630\n",
      "processed: 326/630\n",
      "processed: 327/630\n",
      "processed: 328/630\n",
      "processed: 329/630\n",
      "processed: 330/630\n",
      "processed: 331/630\n",
      "processed: 332/630\n",
      "processed: 333/630\n",
      "processed: 334/630\n",
      "processed: 335/630\n",
      "processed: 336/630\n",
      "processed: 337/630\n",
      "processed: 338/630\n",
      "processed: 339/630\n",
      "processed: 340/630\n",
      "processed: 341/630\n",
      "processed: 342/630\n",
      "processed: 343/630\n",
      "processed: 344/630\n",
      "processed: 345/630\n",
      "processed: 346/630\n",
      "processed: 347/630\n",
      "processed: 348/630\n",
      "processed: 349/630\n",
      "processed: 350/630\n",
      "processed: 351/630\n",
      "processed: 352/630\n",
      "processed: 353/630\n",
      "processed: 354/630\n",
      "processed: 355/630\n",
      "processed: 356/630\n",
      "processed: 357/630\n",
      "processed: 358/630\n",
      "processed: 359/630\n",
      "processed: 360/630\n",
      "processed: 361/630\n",
      "processed: 362/630\n",
      "processed: 363/630\n",
      "processed: 364/630\n",
      "processed: 365/630\n",
      "processed: 366/630\n",
      "processed: 367/630\n",
      "processed: 368/630\n",
      "processed: 369/630\n",
      "processed: 370/630\n",
      "processed: 371/630\n",
      "processed: 372/630\n",
      "processed: 373/630\n",
      "processed: 374/630\n",
      "processed: 375/630\n",
      "processed: 376/630\n",
      "processed: 377/630\n",
      "processed: 378/630\n",
      "processed: 379/630\n",
      "processed: 380/630\n",
      "processed: 381/630\n",
      "processed: 382/630\n",
      "processed: 383/630\n",
      "processed: 384/630\n",
      "processed: 385/630\n",
      "processed: 386/630\n",
      "processed: 387/630\n",
      "processed: 388/630\n",
      "processed: 389/630\n",
      "processed: 390/630\n",
      "processed: 391/630\n",
      "processed: 392/630\n",
      "processed: 393/630\n",
      "processed: 394/630\n",
      "processed: 395/630\n",
      "processed: 396/630\n",
      "processed: 397/630\n",
      "processed: 398/630\n",
      "processed: 399/630\n",
      "processed: 400/630\n",
      "processed: 401/630\n",
      "processed: 402/630\n",
      "processed: 403/630\n",
      "processed: 404/630\n",
      "processed: 405/630\n",
      "processed: 406/630\n",
      "processed: 407/630\n",
      "processed: 408/630\n",
      "processed: 409/630\n",
      "processed: 410/630\n",
      "processed: 411/630\n",
      "processed: 412/630\n",
      "processed: 413/630\n",
      "processed: 414/630\n",
      "processed: 415/630\n",
      "processed: 416/630\n",
      "processed: 417/630\n",
      "processed: 418/630\n",
      "processed: 419/630\n",
      "processed: 420/630\n",
      "processed: 421/630\n",
      "processed: 422/630\n",
      "processed: 423/630\n",
      "processed: 424/630\n",
      "processed: 425/630\n",
      "processed: 426/630\n",
      "processed: 427/630\n",
      "processed: 428/630\n",
      "processed: 429/630\n",
      "processed: 430/630\n",
      "processed: 431/630\n",
      "processed: 432/630\n",
      "processed: 433/630\n",
      "processed: 434/630\n",
      "processed: 435/630\n",
      "processed: 436/630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed: 437/630\n",
      "processed: 438/630\n",
      "processed: 439/630\n",
      "processed: 440/630\n",
      "processed: 441/630\n",
      "processed: 442/630\n",
      "processed: 443/630\n",
      "processed: 444/630\n",
      "processed: 445/630\n",
      "processed: 446/630\n",
      "processed: 447/630\n",
      "processed: 448/630\n",
      "processed: 449/630\n",
      "processed: 450/630\n",
      "processed: 451/630\n",
      "processed: 452/630\n",
      "processed: 453/630\n",
      "processed: 454/630\n",
      "processed: 455/630\n",
      "processed: 456/630\n",
      "processed: 457/630\n",
      "processed: 458/630\n",
      "processed: 459/630\n",
      "processed: 460/630\n",
      "processed: 461/630\n",
      "processed: 462/630\n",
      "processed: 463/630\n",
      "processed: 464/630\n",
      "processed: 465/630\n",
      "processed: 466/630\n",
      "processed: 467/630\n",
      "processed: 468/630\n",
      "processed: 469/630\n",
      "processed: 470/630\n",
      "processed: 471/630\n",
      "processed: 472/630\n",
      "processed: 473/630\n",
      "processed: 474/630\n",
      "processed: 475/630\n",
      "processed: 476/630\n",
      "processed: 477/630\n",
      "processed: 478/630\n",
      "processed: 479/630\n",
      "processed: 480/630\n",
      "processed: 481/630\n",
      "processed: 482/630\n",
      "processed: 483/630\n",
      "processed: 484/630\n",
      "processed: 485/630\n",
      "processed: 486/630\n",
      "processed: 487/630\n",
      "processed: 488/630\n",
      "processed: 489/630\n",
      "processed: 490/630\n",
      "processed: 491/630\n",
      "processed: 492/630\n",
      "processed: 493/630\n",
      "processed: 494/630\n",
      "processed: 495/630\n",
      "processed: 496/630\n",
      "processed: 497/630\n",
      "processed: 498/630\n",
      "processed: 499/630\n",
      "processed: 500/630\n",
      "processed: 501/630\n",
      "processed: 502/630\n",
      "processed: 503/630\n",
      "processed: 504/630\n",
      "processed: 505/630\n",
      "processed: 506/630\n",
      "processed: 507/630\n",
      "processed: 508/630\n",
      "processed: 509/630\n",
      "processed: 510/630\n",
      "processed: 511/630\n",
      "processed: 512/630\n",
      "processed: 513/630\n",
      "processed: 514/630\n",
      "processed: 515/630\n",
      "processed: 516/630\n",
      "processed: 517/630\n",
      "processed: 518/630\n",
      "processed: 519/630\n",
      "processed: 520/630\n",
      "processed: 521/630\n",
      "processed: 522/630\n",
      "processed: 523/630\n",
      "processed: 524/630\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-f6d650c40337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     wrangler.add_data(structure,\n\u001b[1;32m     10\u001b[0m                       \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'total_energy'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                       verbose=True)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m# The verbose flag will print structures that fail to match.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/smol/cofe/wrangler.py\u001b[0m in \u001b[0;36madd_data\u001b[0;34m(self, structure, properties, normalized, weights, verbose, supercell_matrix, site_mapping, raise_failed)\u001b[0m\n\u001b[1;32m    265\u001b[0m         item = self.process_structure(structure, properties, normalized,\n\u001b[1;32m    266\u001b[0m                                       \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupercell_matrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                                       site_mapping, raise_failed)\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/smol/cofe/wrangler.py\u001b[0m in \u001b[0;36mprocess_structure\u001b[0;34m(self, structure, properties, normalized, weights, verbose, supercell_matrix, site_mapping, raise_failed)\u001b[0m\n\u001b[1;32m    473\u001b[0m             fm_row = self._subspace.corr_from_structure(structure,\n\u001b[1;32m    474\u001b[0m                                                         \u001b[0mscmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msupercell_matrix\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                                                         site_mapping=site_mapping)  # noqa\n\u001b[0m\u001b[1;32m    476\u001b[0m             refined_struct = self._subspace.refine_structure(structure,\n\u001b[1;32m    477\u001b[0m                                                              supercell_matrix)\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/smol/cofe/configspace/clusterspace.py\u001b[0m in \u001b[0;36mcorr_from_structure\u001b[0;34m(self, structure, normalized, scmatrix, site_mapping)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0msupercell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_supercell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             extras = [term.value_from_occupancy(occu, supercell)/size\n\u001b[0;32m--> 345\u001b[0;31m                       for term in self._external_terms]\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/smol/cofe/configspace/clusterspace.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0msupercell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_supercell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             extras = [term.value_from_occupancy(occu, supercell)/size\n\u001b[0;32m--> 345\u001b[0;31m                       for term in self._external_terms]\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mextras\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/smol/cofe/extern/ewald.py\u001b[0m in \u001b[0;36mvalue_from_occupancy\u001b[0;34m(self, occu, structure)\u001b[0m\n\u001b[1;32m    149\u001b[0m         ewald_summation = EwaldSummation(ewald_structure, self.real_space_cut,\n\u001b[1;32m    150\u001b[0m                                          self.recip_space_cut, eta=self.eta)\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mewald_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ewald_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mewald_summation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mew_occu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ewald_occu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moccu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewald_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mewald_inds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mewald_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mew_occu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mew_occu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/smol/cofe/extern/ewald.py\u001b[0m in \u001b[0;36mget_ewald_matrix\u001b[0;34m(self, ewald_summation)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \"\"\"\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_term\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'total'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mewald_summation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_energy_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_term\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'reciprocal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mewald_summation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreciprocal_space_energy_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pymatgen/analysis/ewald.py\u001b[0m in \u001b[0;36mtotal_energy_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \"\"\"\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_ewald_terms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pymatgen/analysis/ewald.py\u001b[0m in \u001b[0;36m_calc_ewald_terms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mCalculates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msets\u001b[0m \u001b[0mall\u001b[0m \u001b[0mewald\u001b[0m \u001b[0mterms\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreciprocal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \"\"\"\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecip_forces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_recip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_point_forces\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calc_real_and_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pymatgen/analysis/ewald.py\u001b[0m in \u001b[0;36m_calc_recip\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;31m# Uses the identity sin(x)+cos(x) = 2**0.5 sin(x + pi/4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mexpval\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mg2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wrangler = StructureWrangler(subspace)\n",
    "\n",
    "# you can add any number of properties and name them\n",
    "# whatever you want. You should use something descriptive.\n",
    "# In this case we'll call it 'total_energy'.\n",
    "for ii, valid in enumerate(valid_structs):\n",
    "    print(\"processed: {}/{}\".format(ii, len(valid_structs)))\n",
    "    structure = valid[0]\n",
    "    wrangler.add_data(structure,\n",
    "                      properties={'total_energy': valid[1]},\n",
    "                      verbose=True)\n",
    "# The verbose flag will print structures that fail to match.\n",
    "\n",
    "print(f'\\nTotal structures that match {wrangler.num_structures}/{len(valid_structs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Training\n",
    "\n",
    "Training a cluster expansion is one of the most critical steps. This is how you get **effective cluster interactions (ECI's)**. To do so you need an estimator class that implements some form of regression model. In this case we will use simple least squares regression using the `LinearRegression` estimator from `scikit-learn`.\n",
    "\n",
    "In `smol` the coefficients from the fit are not exactly the ECI's but the ECI times the multiplicity of their orbit.\n",
    "\n",
    "Currently we also have the old l1regs estimator from pyabinitio in `smol.learn` as `WDRLasso`, but it will likely be deprecated and removed at some point..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrangler.feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Set fit_intercept to False because we already do this using\n",
    "# the empty cluster.\n",
    "estimator = LinearRegression(fit_intercept=False)\n",
    "estimator.fit(wrangler.feature_matrix,\n",
    "              wrangler.get_property_vector('total_energy'))\n",
    "coefs = estimator.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1) Check the quality of the fit\n",
    "There are many ways to evaluate the quality of a fit. The simplest involve stadard training set prediction error metrics. But when evaluating a CE more seriously we need to consider further metrics and how the CE will be used.\n",
    "Here we will just look at in sample mean squared error and max error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE 0.011030076908761016 eV/prim\n",
      "MAX 0.022826186581731633 eV/prim\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, max_error\n",
    "\n",
    "train_predictions = np.dot(wrangler.feature_matrix, coefs)\n",
    "\n",
    "rmse = mean_squared_error(wrangler.get_property_vector('total_energy'),\n",
    "                          train_predictions, squared=False)\n",
    "maxer = max_error(wrangler.get_property_vector('total_energy'),\n",
    "                  train_predictions)\n",
    "\n",
    "print(f'RMSE {rmse} eV/prim')\n",
    "print(f'MAX {maxer} eV/prim')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) The cluster expansion\n",
    "Now we can use the above work to create the `ClusterExpansion`. The cluster expansion can be used to predict the fitted property for new structures, either for testing quality or for simulations such as in Monte Carlo.\n",
    "Note that when using the `predict` function, the cluster expansion will have to match the given structure if it has not seen it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted energy for a structure with composition Li+4 Ni3+4 Ni4+2 O2-12 is -35.44704535541771 eV/prim.\n",
      "\n",
      "The fitted coefficients are:\n",
      "[-3.44424307e+01  1.52944807e+00  1.52944807e+00 -7.11937730e-02\n",
      "  1.45252212e-01  4.23347433e-02 -9.28828072e-02  1.51736904e-02\n",
      " -5.89723850e-02  2.69095444e-02  1.10210719e-02]\n",
      "\n",
      "The effective cluster interactions are:\n",
      "[-3.44424307e+01  1.52944807e+00  1.52944807e+00 -1.18656288e-02\n",
      "  4.84174038e-02  1.41115811e-02 -1.54804679e-02  2.52894839e-03\n",
      " -9.82873083e-03  1.34547722e-02  5.51053597e-03]\n",
      "\n",
      "ClusterExpansion:\n",
      "    Prim Composition: Li+0.5 Ni3+0.5 Ni4+0.5 O2-2\n",
      " Num fit structures: 27\n",
      "Num orbit functions: 11\n",
      "    [Orbit]  id: 0  \n",
      "        bit       eci\n",
      "        [X]       -34.4\n",
      "    [Orbit]  id: 1   size: 1   radius: 0.0 \n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        1     [0]       1.529   -0.062       0.426        0.651\n",
      "    [Orbit]  id: 2   size: 1   radius: 0.0 \n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        2     [0]       1.529   -0.062       0.426        0.651\n",
      "    [Orbit]  id: 3   size: 2   radius: 2.97\n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        3     [0 0]     -0.071  0.230        0.310        -0.022\n",
      "    [Orbit]  id: 4   size: 2   radius: 2.97\n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        4     [0 0]     0.145   0.218        0.442        0.064\n",
      "    [Orbit]  id: 5   size: 2   radius: 2.97\n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        5     [0 0]     0.042   0.111        0.342        0.014\n",
      "    [Orbit]  id: 6   size: 2   radius: 4.2 \n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        6     [0 0]     -0.093  0.337        0.325        -0.030\n",
      "    [Orbit]  id: 7   size: 3   radius: 2.97\n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        7     [0 0 0]   0.015   -0.070       0.357        0.005\n",
      "    [Orbit]  id: 8   size: 3   radius: 2.97\n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        8     [0 0 0]   -0.059  -0.029       0.350        -0.021\n",
      "    [Orbit]  id: 9   size: 3   radius: 2.97\n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        9     [0 0 0]   0.027   -0.062       0.385        0.010\n",
      "    [Orbit]  id: 10  size: 3   radius: 2.97\n",
      "        id    bit       eci     feature avg  feature std  eci*std\n",
      "        10    [0 0 0]   0.011   -0.111       0.416        0.005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expansion = ClusterExpansion(subspace,\n",
    "                             coefficients=coefs,\n",
    "                             feature_matrix=wrangler.feature_matrix)\n",
    "\n",
    "structure = np.random.choice(wrangler.structures)\n",
    "prediction = expansion.predict(structure, normalize=True)\n",
    "\n",
    "print(f'The predicted energy for a structure with composition '\n",
    "      f'{structure.composition} is {prediction} eV/prim.\\n')\n",
    "print(f'The fitted coefficients are:\\n{expansion.coefs}\\n')\n",
    "print(f'The effective cluster interactions are:\\n{expansion.eci}\\n')\n",
    "print(expansion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Saving your work\n",
    "All core classes in `smol` are `MSONables` and so can be saved using their `as_dict` methods or better yet with `monty.serialization.dumpfn`.\n",
    "\n",
    "Currently there is also a convenience function in `smol` that will nicely save all of your work for you in a standardized way. Work saved with the `save_work` function is saved as a dictionary with standardized names for the classes. Since a work flow should only contain 1 of each core classes the function will complain if you give it two of the same class (i.e. two wranglers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smol.io import save_work\n",
    "\n",
    "file_path = 'data/basic_ce.mson'\n",
    "# we can save the subspace as well, but since both the wrangler\n",
    "# and the expansion have it, there is no need to do so.\n",
    "save_work(file_path, wrangler, expansion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1) Loading previously saved work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructureWrangler: <class 'smol.cofe.wrangler.StructureWrangler'>\n",
      "\n",
      "ClusterExpansion: <class 'smol.cofe.expansion.ClusterExpansion'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from smol.io import load_work\n",
    "\n",
    "work = load_work(file_path)\n",
    "for name, obj in work.items():\n",
    "    print(f'{name}: {type(obj)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
