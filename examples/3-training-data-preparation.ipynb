{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from monty.serialization import loadfn\n",
    "from pymatgen import Structure\n",
    "from smol.cofe import ClusterSubspace, StructureWrangler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Preparing a `StructureWrangler`\n",
    "Training structures and target data are handled by the `StructureWrangler` class. The class obtains the features and corresponding feature matrix based on the underlying `ClusterSubspace` provided.\n",
    "\n",
    "In the most simply settings we just use the feature matrix our supplied total energy from DFT to fit a cluster expansion. But it many cases we may want to improve our fit quality or reduce the model complexity by modifying the target property (i.e. using a reference energy or the energy of mixing) and/or by weighing structures based on some importance metric (i.e. by energy above hull). Using the `StructureWrangler` we can create this modified fitting data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total structures that match 27/31\n"
     ]
    }
   ],
   "source": [
    "# Load the raw data\n",
    "# load the prim structure\n",
    "lno_prim = loadfn('data/lno_prim.json')\n",
    "    \n",
    "# load the fitting data\n",
    "with open('data/lno_fitting_data.json', 'r') as f:\n",
    "    lno_data = [(Structure.from_dict(x['s']), x['toten']) for x in json.load(f)]\n",
    "\n",
    "    \n",
    "# create a cluster subspace\n",
    "subspace = ClusterSubspace.from_radii(lno_prim,\n",
    "                                      radii={2: 5, 3: 4.1},\n",
    "                                      basis='sinusoid',\n",
    "                                      supercell_size='O2-')\n",
    "\n",
    "# create the structre wrangler\n",
    "wrangler = StructureWrangler(subspace)\n",
    "\n",
    "# add the raw data\n",
    "for structure, tot_energy in lno_data:\n",
    "    wrangler.add_data(structure,\n",
    "                      properties={'total_energy': tot_energy})\n",
    "\n",
    "print(f'\\nTotal structures that match {wrangler.num_structures}/{len(lno_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Modifying and adding new target properties\n",
    "\n",
    "Now that we have access to the structures that match to our cluster subspace, and access to the raw and normalized target properties, we can easily create new modifiend target properties to fit to.\n",
    "\n",
    "For a simple example say we simply want to set the minimum energy in our data as a new reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the minimum energy. Calling the get_property_vector\n",
    "# will by default give you the property normalized per prim \n",
    "# (you should always used consistently normalized data when fitting)\n",
    "min_energy = min(wrangler.get_property_vector('total_energy'))\n",
    "\n",
    "# simply create a new re-reference energy\n",
    "reref_energy_vect = wrangler.get_property_vector('total_energy') - min_energy\n",
    "\n",
    "# add it as a new property to the wrangler\n",
    "# in this case since the reref energy is a normalized\n",
    "# quantity we need to explicitly tell the wrangler\n",
    "wrangler.add_properties('rereferenced_energy',\n",
    "                        reref_energy_vect,\n",
    "                        normalized=False)\n",
    "\n",
    "# Now we have to properties in the wrangler that we can\n",
    "# use to fit a cluster expansion, the total energy\n",
    "# and the rereference energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1) Another example of modifying target properties\n",
    "\n",
    "We can do more complex modifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Obtaining and adding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Filtering structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matx_dev",
   "language": "python",
   "name": "matx_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
